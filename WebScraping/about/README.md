ğŸ“Œ Projeto de AutomaÃ§Ã£o e Armazenamento de Dados
ğŸ“– Sobre o Projeto
Este projeto tem como objetivo automatizar o download de um arquivo XLSX a partir de um site, processar seus dados e armazenÃ¡-los em um banco de dados MySQL. Ele utiliza Selenium para interagir com a web, Pandas para manipulaÃ§Ã£o dos dados e MySQL Connector para armazenÃ¡-los de forma eficiente.

AlÃ©m disso, foi desenvolvida uma interface grÃ¡fica com Tkinter, permitindo o monitoramento em tempo real do processo e a geraÃ§Ã£o de logs organizados. O projeto tambÃ©m inclui um sistema de cancelamento, que permite interromper a automaÃ§Ã£o a qualquer momento.

ğŸš€ Funcionalidades
AutomaÃ§Ã£o Web: O Selenium acessa o site e baixa automaticamente o arquivo XLSX.

Processamento de Dados: Os dados da planilha sÃ£o organizados e preparados para inserÃ§Ã£o no banco de dados.

Banco de Dados: CriaÃ§Ã£o de tabelas dinÃ¢micas e inserÃ§Ã£o dos dados no MySQL.

Interface GrÃ¡fica (GUI): ExibiÃ§Ã£o do progresso da automaÃ§Ã£o, botÃµes para iniciar, cancelar e gerar logs.

GeraÃ§Ã£o de Logs: Registro de todas as operaÃ§Ãµes para acompanhamento e depuraÃ§Ã£o.

Cancelamento: Permite interromper a automaÃ§Ã£o a qualquer momento.

ğŸ“ Estrutura do Projeto
WEBSCRAPING/
â”œâ”€â”€ about/                          # InformaÃ§Ãµes sobre o projeto
â”œâ”€â”€ database/                       # Arquivos relacionados ao banco de dados
â”‚   â”œâ”€â”€ conexao/                    # ConexÃ£o com o banco de dados
â”‚   â”‚   â””â”€â”€ MySQLConnection.py      # Classe para gerenciar a conexÃ£o MySQL
â”‚   â””â”€â”€ consultas/                  # Consultas e operaÃ§Ãµes no banco de dados
â”‚       â””â”€â”€ insert.py               # Script para inserir dados no MySQL
â”œâ”€â”€ download/                       # Arquivos baixados pelo web scraping
â”‚   â””â”€â”€ dados_emergy_*.xlsx         # Arquivos Excel baixados
â”œâ”€â”€ logs/                           # Logs gerados durante a execuÃ§Ã£o
â”‚   â””â”€â”€ automation_log.log          # Arquivo de log principal
â”œâ”€â”€ interface/                      # Interface grÃ¡fica do projeto
â”‚   â””â”€â”€ app_interface.py            # Interface grÃ¡fica usando Tkinter
â”œâ”€â”€ scripts/                        # Scripts principais do projeto
â”‚   â”œâ”€â”€ main.py                     # Script principal de web scraping
â”‚   â””â”€â”€ logging_config.py           # ConfiguraÃ§Ã£o do sistema de logs
â”œâ”€â”€ .env                            # VariÃ¡veis de ambiente (credenciais do banco de dados)
â”œâ”€â”€ requirements.txt                # DependÃªncias do projeto
â”œâ”€â”€ README.md                       # DocumentaÃ§Ã£o do projeto
â””â”€â”€ Diagrama WebScraping.drawio.png # Diagrama de fluxo do projeto
ğŸ”§ Tecnologias Utilizadas
Python 3.x

Selenium â†’ AutomaÃ§Ã£o web

Pandas â†’ ManipulaÃ§Ã£o de dados

MySQL Connector â†’ ComunicaÃ§Ã£o com o banco de dados

dotenv â†’ Gerenciamento de variÃ¡veis de ambiente

WebDriver Manager â†’ Gerenciamento do ChromeDriver

openpyxl â†’ ManipulaÃ§Ã£o de arquivos Excel

Tkinter â†’ Interface grÃ¡fica para interaÃ§Ã£o com o usuÃ¡rio

Threading â†’ ExecuÃ§Ã£o de tarefas em segundo plano

Logging â†’ GeraÃ§Ã£o de logs detalhados

âš™ï¸ ConfiguraÃ§Ã£o do Ambiente
1ï¸âƒ£ Clonar o repositÃ³rio
git clone https://github.com/seu-usuario/webscraping.git
cd webscraping

2ï¸âƒ£ Criar e ativar um ambiente virtual (opcional)
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

3ï¸âƒ£ Instalar as dependÃªncias
pip install -r requirements.txt

4ï¸âƒ£ Configurar o arquivo .env
Crie um arquivo .env na raiz do projeto e adicione as credenciais do banco de dados:

DB_HOST=seu_host
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
DB_NAME=seu_banco_de_dados
DB_PORT=sua_porta

ğŸš€ Como Executar o Projeto
1. Executar a Interface GrÃ¡fica
python interface/app_interface.py

2. Na interface, clique em "Iniciar AutomaÃ§Ã£o"
O Selenium abrirÃ¡ o navegador (em modo headless, se configurado), acessarÃ¡ o site e farÃ¡ o download do arquivo XLSX.

O arquivo serÃ¡ salvo na pasta download/.

O script processarÃ¡ os dados e os armazenarÃ¡ nas tabelas correspondentes no banco de dados MySQL.

3. Acompanhe o Progresso
A interface grÃ¡fica exibirÃ¡ logs em tempo real e uma barra de progresso.

Caso necessÃ¡rio, clique em "Cancelar" para interromper a automaÃ§Ã£o.

4. Para visualizar os logs, clique em "Gerar Logs"
Um relatÃ³rio completo das operaÃ§Ãµes serÃ¡ exibido no arquivo automation_log.log.

ğŸ“Š Banco de Dados
O projeto cria automaticamente as tabelas no banco de dados com base nas abas da planilha XLSX e insere os dados de forma dinÃ¢mica. As tabelas sÃ£o nomeadas de acordo com as abas do arquivo Excel, e os dados sÃ£o limpos para evitar problemas com caracteres invÃ¡lidos.

ğŸ“ Contato
Caso tenha dÃºvidas ou sugestÃµes, entre em contato:

Email: erickbritto060@gmail.com

GitHub: https://github.com/erkbritto/WebScraping

LinkedIn: https://www.linkedin.com/in/erkbritto/

instagram: https://www.instagram.com/erkbritto/